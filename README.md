# Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens
Repository of the CHI'23 paper "Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens"

Over the last few years, we have seen many approaches using tangibles to address the limited expressiveness of touchscreens. Mainstream tangible detection uses fiducial markers embedded in the tangibles. However, the coarse sensor size of capacitive touchscreens makes tangibles bulky, limiting their usefulness. We propose a novel deep-learning super-resolution network to facilitate fiducial tangibles on capacitive touchscreens better. In detail, our network super-resolves the markers enabling off-the-shelf detection algorithms to track tangibles reliably. Our network generalizes to unseen marker sets, such as AprilTag, ArUco, and ARToolKit. Therefore, we are not limited to a fixed number of distinguishable objects and do not require data collection and network training for new fiducial markers. With extensive evaluation, including real-world users and five showcases, we demonstrate the applicability of our open-source approach on commodity mobile devices and further highlight the potential of tangibles on capacitive touchscreens.

## Citing our work
This work can be cited as follows:
<pre>
@inproceedings{rusu2023deep,
title = {Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens},
author = {Rusu, Marius and Mayer, Sven},
year = {2023},
booktitle = {Proceedings of the 42st ACM Conference on Human Factors in Computing Systems},
address = {Hamburg, Germany},
serires = {CHI'23},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi={10.1145/3544548.3580987}
}
<?pre>
